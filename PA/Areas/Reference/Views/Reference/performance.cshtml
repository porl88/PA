@{
	ViewBag.Title = "Best Practices for Speeding Up Your Web Site | Reference";
}

@section Breadcrumb {
	<ol class="breadcrumb">
		<li>@Html.ActionLink("Home", "index", "home", new { area = "" }, null)</li>
		<li>@Html.ActionLink("Reference", "index", "reference")</li>
		<li>Performance</li>
	</ol>
}

<article>
	
<h1>Best Practices for Speeding Up Your Web Site</h1>

<ul>
	<li><a href="#content">Content</a></li>
	<li><a href="#server">Server</a></li>
	<li><a href="#cookie">Cookie</a></li>
	<li><a href="#jscss">JavaScript &amp; <abbr title="Cascading Style Sheet">CSS</abbr></a></li>
	<li><a href="#css"><abbr title="Cascading Style Sheet">CSS</abbr></a></li>
	<li><a href="#js">Javascript</a></li>
	<li><a href="#images">Images</a></li>
	<li><a href="#mobile">Mobile</a></li>
</ul>


<h2 id="content">Content</h2>

<h3>Minimise <abbr title="Hypertext Transfer Protocol">HTTP</abbr> Requests</h3>
<p>80% of the end-user response time is spent on the front-end. Most of this time is tied up in downloading all the components in the page: images, stylesheets, scripts, Flash, etc. Reducing the number of components in turn reduces the number of <abbr title="Hypertext Transfer Protocol">HTTP</abbr> requests required to render the page. This is the key to faster pages. </p>
<p>One way to reduce the number of components in the page is to simplify the page's design. But is there a way to build pages with richer content while also achieving fast response times? Here are some techniques for reducing the number of <abbr title="Hypertext Transfer Protocol">HTTP</abbr> requests, while still supporting rich page designs.</p>
<p><strong>Combined files</strong> are a way to reduce the number of <abbr title="Hypertext Transfer Protocol">HTTP</abbr> requests by combining all scripts into a single script, and similarly combining all <abbr title="Cascading Style Sheet">CSS</abbr> into a single stylesheet. Combining files is more challenging when the scripts and stylesheets vary from page to page, but making this part of your release process improves response times.</p>
<p><a href="http://alistapart.com/articles/sprites" target="_blank"><strong><abbr title="Cascading Style Sheet">CSS</abbr> Sprites</strong></a> are the preferred method for reducing the number of image requests. Combine your background images into a single image and use the <abbr title="Cascading Style Sheet">CSS</abbr> <code>background-image</code> and <code>background-position</code> properties to display the desired image segment.</p>
<p><a href="http://www.w3.org/TR/html401/struct/objects.html#h-13.6" target="_blank"><strong>Image maps</strong></a> combine multiple images into a single image. The overall size is about the same, but reducing the number of <abbr title="Hypertext Transfer Protocol">HTTP</abbr> requests speeds up the page. Image maps only work if the images are contiguous in the page, such as a navigation bar. Defining the coordinates of image maps can be tedious and error prone. Using image maps for navigation is not accessible too, so it's not recommended.</p>
<p><strong>Inline images</strong> use the <a href="http://tools.ietf.org/html/rfc2397" target="_blank"><code>data:</code> URL scheme</a> to embed the image data in the actual page. This can increase the size of your <abbr title="Hypertext Markup Language">HTML</abbr> document. Combining inline images into your (cached) stylesheets is a way to reduce <abbr title="Hypertext Transfer Protocol">HTTP</abbr> requests and avoid increasing the size of your pages. Inline images are not yet supported across all major browsers.</p>
<p>Reducing the number of <abbr title="Hypertext Transfer Protocol">HTTP</abbr> requests in your page is the place to start. This is the most important guideline for improving performance for first time visitors. As described in Tenni Theurer's blog post <a href="http://yuiblog.com/blog/2007/01/04/performance-research-part-2/" target="_blank">Browser Cache Usage - Exposed!</a>, 40-60% of daily visitors to your site come in with an empty cache. Making your page fast for these first time visitors is key to a better user experience.</p>


<h3>Reduce DNS Lookups</h3>
<p>The Domain Name System (DNS) maps hostnames to IP addresses, just as phonebooks map people's names to their phone numbers. When you type <kbd>@Request.Url.Host</kbd> into your browser, a DNS resolver contacted by the browser returns that server's IP address. DNS has a cost. It typically takes 20-120 milliseconds for DNS to lookup the IP address for a given hostname. The browser can't download anything from this hostname until the DNS lookup is completed. </p>
<p>DNS lookups are cached for better performance. This caching can occur on a special caching server, maintained by the user's ISP or local area network, but there is also caching that occurs on the individual user's computer. The DNS information remains in the operating system's DNS cache (the "DNS Client service" on Microsoft Windows). Most browsers have their own caches, separate from the operating system's cache. As long as the browser keeps a DNS record in its own cache, it doesn't bother the operating system with a request for the record.</p>
<p>Internet Explorer caches DNS lookups for 30 minutes by default, as specified by the <code>DnsCacheTimeout</code> registry setting. Firefox caches DNS lookups for 1 minute, controlled by the <code>network.dnsCacheExpiration</code> configuration setting. (Fasterfox changes this to 1 hour.)</p>
<p>When the client's DNS cache is empty (for both the browser and the operating system), the number of DNS lookups is equal to the number of unique hostnames in the web page. This includes the hostnames used in the page's URL, images, script files, stylesheets, Flash objects, etc. Reducing the number of unique hostnames reduces the number of DNS lookups. </p>
<p>Reducing the number of unique hostnames has the potential to reduce the amount of parallel downloading that takes place in the page. Avoiding DNS lookups cuts response times, but reducing parallel downloads may increase response times. My guideline is to split these components across at least two but no more than four hostnames. This results in a good compromise between reducing DNS lookups and allowing a high degree of parallel downloads.</p>

<h3>Avoid Redirects</h3>
<p>Redirects are accomplished using the 301 and 302 status codes. Here's an example of the <abbr title="Hypertext Transfer Protocol">HTTP</abbr> headers in a 301 response:</p>
<p><code><abbr title="Hypertext Transfer Protocol">HTTP</abbr> /1.1 301 Moved Permanently Location: http://example.com/newuri Content-Type: text/html</code></p>
<p>The browser automatically takes the user to the URL specified in the <code>Location</code> field. All the information necessary for a redirect is in the headers. The body of the response is typically empty. Despite their names, neither a 301 nor a 302 response is cached in practice unless additional headers, such as <code>Expires</code> or <code>Cache-Control</code>, indicate it should be. The meta refresh tag and JavaScript are other ways to direct users to a different URL, but if you must do a redirect, the preferred technique is to use the standard 3xx <abbr title="Hypertext Transfer Protocol">HTTP</abbr> status codes, primarily to ensure the back button works correctly.</p>
<p>The main thing to remember is that redirects slow down the user experience. Inserting a redirect between the user and the <abbr title="Hypertext Markup Language">HTML</abbr> document delays everything in the page since nothing in the page can be rendered and no components can start being downloaded until the <abbr title="Hypertext Markup Language">HTML</abbr> document has arrived.</p>
<p>One of the most wasteful redirects happens frequently and web developers are generally not aware of it. It occurs when a trailing slash (/) is missing from a URL that should otherwise have one. For example, going to http://www.science.com/astrology results in a 301 response containing a redirect to http://www.science.com/astrology/ (notice the added trailing slash). This is fixed in Apache by using <code>Alias</code> or <code>mod_rewrite</code>, or the <code>DirectorySlash</code> directive if you're using Apache handlers.</p>
<p>Connecting an old web site to a new one is another common use for redirects. Others include connecting different parts of a website and directing the user based on certain conditions (type of browser, type of user account, etc.). Using a redirect to connect two web sites is simple and requires little additional coding. Although using redirects in these situations reduces the complexity for developers, it degrades the user experience. Alternatives for this use of redirects include using <code>Alias</code> and <code>mod_rewrite</code> if the two code paths are hosted on the same server. If a domain name change is the cause of using redirects, an alternative is to create a CNAME (a DNS record that creates an alias pointing from one domain name to another) in combination with <code>Alias</code> or <code>mod_rewrite</code>.</p>

<h3>Make <abbr title="Asynchronous JavaScript and XML">Ajax</abbr> Cacheable</h3>
<p>One of the cited benefits of <abbr title="Asynchronous JavaScript and XML">Ajax</abbr> is that it provides instantaneous feedback to the user because it requests information asynchronously from the backend web server. However, using <abbr title="Asynchronous JavaScript and XML">Ajax</abbr> is no guarantee that the user won't be twiddling his thumbs waiting for those asynchronous JavaScript and <abbr title="Extensible Markup Language">XML</abbr> responses to return. In many applications, whether or not the user is kept waiting depends on how <abbr title="Asynchronous JavaScript and XML">Ajax</abbr> is used. For example, in a web-based email client the user will be kept waiting for the results of an <abbr title="Asynchronous JavaScript and XML">Ajax</abbr> request to find all the email messages that match their search criteria. It's important to remember that "asynchronous" does not imply "instantaneous".</p>
<p>To improve performance, it's important to optimise these <abbr title="Asynchronous JavaScript and XML">Ajax</abbr> responses. The most important way to improve the performance of <abbr title="Asynchronous JavaScript and XML">Ajax</abbr> is to make the responses cacheable, as discussed in <a href="#expires">Add an Expires or a Cache-Control Header</a>. Some of the other rules also apply to <abbr title="Asynchronous JavaScript and XML">Ajax</abbr>:</p>
<ul>
	<li><a href="#gzip">Gzip Components</a></li>
	<li><a href="#dns_lookups">Reduce DNS Lookups</a></li>
	<li><a href="#minify">Minify JavaScript</a></li>
	<li><a href="#redirects">Avoid Redirects</a></li>
	<li><a href="#etags">Configure ETags</a></li>
</ul>
<p>Let's look at an example. A Web 2.0 email client might use <abbr title="Asynchronous JavaScript and XML">Ajax</abbr> to download the user's address book for autocompletion. If the user hasn't modified her address book since the last time she used the email web app, the previous address book response could be read from cache if that <abbr title="Asynchronous JavaScript and XML">Ajax</abbr> response was made cacheable with a future Expires or Cache-Control header. The browser must be informed when to use a previously cached address book response versus requesting a new one. This could be done by adding a timestamp to the address book <abbr title="Asynchronous JavaScript and XML">Ajax</abbr> URL indicating the last time the user modified her address book, for example, <code>&amp;t=1190241612</code>. If the address book hasn't been modified since the last download, the timestamp will be the same and the address book will be read from the browser's cache eliminating an extra <abbr title="Hypertext Transfer Protocol">HTTP</abbr> roundtrip. If the user has modified her address book, the timestamp ensures the new URL doesn't match the cached response, and the browser will request the updated address book entries.</p>
<p>Even though your <abbr title="Asynchronous JavaScript and XML">Ajax</abbr> responses are created dynamically, and might only be applicable to a single user, they can still be cached. Doing so will make your Web 2.0 apps faster.</p>

<h3>Post-Load Components</h3>
<p>You can take a closer look at your page and ask yourself: "What's absolutely required in order to render the page initially?". The rest of the content and components can wait.</p>
<p>JavaScript is an ideal candidate for splitting before and after the onload event. For example if you have JavaScript code and libraries that do drag and drop and animations, those can wait, because dragging elements on the page comes after the initial rendering. Other places to look for candidates for post-loading include hidden content (content that appears after a user action) and images below the fold.</p>
<p>Tools to help you out in your effort: <a href="http://developer.yahoo.com/yui/imageloader/" target="_blank">YUI Image Loader</a> allows you to delay images below the fold and the <a href="http://developer.yahoo.com/yui/get/" target="_blank">YUI Get utility</a> is an easy way to include <abbr title="JavaScript">JS</abbr> and <abbr title="Cascading Style Sheet">CSS</abbr> on the fly. For an example in the wild take a look at <a href="http://www.yahoo.com" target="_blank">Yahoo! Home Page</a> with Firebug's Net Panel turned on.</p>
<p>It's good when the performance goals are inline with other web development best practices. In this case, the idea of progressive enhancement tells us that JavaScript, when supported, can improve the user experience but you have to make sure the page works even without JavaScript. So after you've made sure the page works fine, you can enhance it with some post-loaded scripts that give you more bells and whistles such as drag and drop and animations.</p>

<h3>Preload Components</h3>
<p>Preload may look like the opposite of post-load, but it actually has a different goal. By preloading components you can take advantage of the time the browser is idle and request components (like images, styles and scripts) you'll need in the future. This way when the user visits the next page, you could have most of the components already in the cache and your page will load much faster for the user.</p>
<p>There are actually several types of preloading:</p>
<ul>
	<li><em>Unconditional</em> preload - as soon as onload fires, you go ahead and fetch some extra components. Check google.com for an example of how a sprite image is requested onload. This sprite image is not needed on the google.com homepage, but it is needed on the consecutive search result page.</li>
	<li><em>Conditional</em> preload - based on a user action you make an educated guess where the user is headed next and preload accordingly. On <a href="http://search.yahoo.com" target="_blank">search.yahoo.com</a> you can see how some extra components are requested after you start typing in the input box.</li>
	<li><em>Anticipated</em> preload - preload in advance before launching a redesign. It often happens after a redesign that you hear: "The new site is cool, but it's slower than before". Part of the problem could be that the users were visiting your old site with a full cache, but the new one is always an empty cache experience. You can mitigate this side effect by preloading some components before you even launched the redesign. Your old site can use the time the browser is idle and request images and scripts that will be used by the new site</li>
</ul>

<h3>Reduce the Number of <abbr title="Document Object Model">DOM</abbr> Elements</h3>
<p>A complex page means more bytes to download and it also means slower <abbr title="Document Object Model">DOM</abbr> access in JavaScript. It makes a difference if you loop through 500 or 5000 <abbr title="Document Object Model">DOM</abbr> elements on the page when you want to add an event handler for example.</p>
<p>A high number of <abbr title="Document Object Model">DOM</abbr> elements can be a symptom that there's something that should be improved with the markup of the page without necessarily removing content. Are you using nested tables for layout purposes? Are you throwing in more <code>&lt;div&gt;</code>s only to fix layout issues? Maybe there's a better and more semantically correct way to do your markup.</p>
<p>You can use a reset stylesheet to help you strip away browsers' default formatting. <a href="http://meyerweb.com/eric/tools/css/reset/" target="_blank">Click here for an example of a reset.css file</a>. The goal of a reset stylesheet is to reduce browser inconsistencies in things like default line heights, margins and font sizes of headings, and so on.</p>
<p>This is a chance to start fresh and think about your markup, for example use <code>&lt;div&gt;</code>s only when it makes sense semantically, and not because it renders a new line.</p>
<p>The number of <abbr title="Document Object Model">DOM</abbr> elements is easy to test, just type in Firebug's console:<br /><code>document.getElementsByTagName('*').length</code></p>
<p>And how many <abbr title="Document Object Model">DOM</abbr> elements are too many? Check other similar pages that have good markup. For example the <a href="http://www.yahoo.com" target="_blank">Yahoo! Home Page</a> is a pretty busy page and still under 700 elements (<abbr title="Hypertext Markup Language">HTML</abbr> tags).</p>

<h3>Split Components Across Domains</h3>
<p>Splitting components allows you to maximise parallel downloads. Make sure you're using not more than 2-4 domains because of the DNS lookup penalty. For example, you can host your <abbr title="Hypertext Markup Language">HTML</abbr> and dynamic content on <code>www.example.org</code> and split static components between <code>static1.example.org</code> and <code>static2.example.org</code></p>
<p>For more information check <cite><a href="http://yuiblog.com/blog/2007/04/11/performance-research-part-4/" target="_blank">Maximising Parallel Downloads in the Carpool Lane</a></cite> by Tenni Theurer and Patty Chi.</p>

<h3>Minimise the Number of iframes</h3>
<p>Iframes allow an <abbr title="Hypertext Markup Language">HTML</abbr> document to be inserted in the parent document. It's important to understand how iframes work so they can be used effectively.</p>
<p><code>&lt;iframe&gt;</code> pros:</p>
<ul>
	<li>Helps with slow third-party content like badges and ads</li>
	<li>Security sandbox</li>
	<li>Download scripts in parallel</li>
</ul>
<p><code>&lt;iframe&gt;</code> cons:</p>
<ul>
	<li>Costly even if blank</li>
	<li>Blocks page onload</li>
	<li>Non-semantic</li>
</ul>

<h3>No 404s</h3>
<p><abbr title="Hypertext Transfer Protocol">HTTP</abbr> requests are expensive so making an <abbr title="Hypertext Transfer Protocol">HTTP</abbr> request and getting a useless response (i.e. 404 Not Found) is totally unnecessary and will slow down the user experience without any benefit.</p>
<p>Some sites have helpful 404s "Did you mean X?", which is great for the user experience but also wastes server resources (like database, etc). Particularly bad is when the link to an external JavaScript is wrong and the result is a 404. First, this download will block parallel downloads. Next the browser may try to parse the 404 response body as if it were JavaScript code, trying to find something usable in it.</p>


<h2 id="server">Server</h2>

<h3>Use a Content Delivery Network</h3>
<p>The user's proximity to your web server has an impact on response times. Deploying your content across multiple, geographically dispersed servers will make your pages load faster from the user's perspective. But where should you start?</p>
<p>As a first step to implementing geographically dispersed content, don't attempt to redesign your web application to work in a distributed architecture. Depending on the application, changing the architecture could include daunting tasks such as synchronizing session state and replicating database transactions across server locations. Attempts to reduce the distance between users and your content could be delayed by, or never pass, this application architecture step. </p>
<p>Remember that 80-90% of the end-user response time is spent downloading all the components in the page: images, stylesheets, scripts, Flash, etc. This is the <em>Performance Golden Rule</em>. Rather than starting with the difficult task of redesigning your application architecture, it's better to first disperse your static content. This not only achieves a bigger reduction in response times, but it's easier thanks to content delivery networks.</p>
<p>A content delivery network (<abbr title="Content Delivery Network">CDN</abbr> ) is a collection of web servers distributed across multiple locations to deliver content more efficiently to users. The server selected for delivering content to a specific user is typically based on a measure of network proximity. For example, the server with the fewest network hops or the server with the quickest response time is chosen.</p>
<p>Some large Internet companies own their own <abbr title="Content Delivery Network">CDN</abbr> , but it's cost-effective to use a <abbr title="Content Delivery Network">CDN</abbr> service provider, such as <a href="http://www.akamai.com/" target="_blank">Akamai Technologies</a>, <a href="http://www.mirror-image.com/" target="_blank">Mirror Image Internet</a>, or <a href="http://www.limelightnetworks.com/" target="_blank">Limelight Networks</a>. For start-up companies and private web sites, the cost of a <abbr title="Content Delivery Network">CDN</abbr> service can be prohibitive, but as your target audience grows larger and becomes more global, a <abbr title="Content Delivery Network">CDN</abbr> is necessary to achieve fast response times. Moving static content off application web servers to a <abbr title="Content Delivery Network">CDN</abbr> can improve end-user response times by 20% or more. Switching to a <abbr title="Content Delivery Network">CDN</abbr> is a relatively easy code change that will dramatically improve the speed of your web site.</p>

<h3>Add an Expires or a Cache-Control Header</h3>
<p>There are two things in this rule:</p>
<ul>
	<li>For static components: implement "Never expire" policy by setting far future <code>Expires</code> header</li>
	<li>For dynamic components: use an appropriate <code>Cache-Control</code> header to help the browser with conditional requests</li>
</ul>
<p>Web page designs are getting richer and richer, which means more scripts, stylesheets, images, and Flash in the page. A first-time visitor to your page may have to make several <abbr title="Hypertext Transfer Protocol">HTTP</abbr> requests, but by using the Expires header you make those components cacheable. This avoids unnecessary <abbr title="Hypertext Transfer Protocol">HTTP</abbr> requests on subsequent page views. Expires headers are most often used with images, but they should be used on <em>all</em> components including scripts, stylesheets, and Flash components.</p>
<p>Browsers (and proxies) use a cache to reduce the number and size of <abbr title="Hypertext Transfer Protocol">HTTP</abbr> requests, making web pages load faster. A web server uses the Expires header in the <abbr title="Hypertext Transfer Protocol">HTTP</abbr> response to tell the client how long a component can be cached. This is a far future Expires header, telling the browser that this response won't be stale until April 15, 2010. </p>
<p><code>Expires: Thu, 15 Apr 2010 20:00:00 GMT</code></p>
<p>If your server is Apache, use the ExpiresDefault directive to set an expiration date relative to the current date. This example of the ExpiresDefault directive sets the Expires date 10 years out from the time of the request.</p>
<p><code>ExpiresDefault "access plus 10 years"</code></p>
<p>Keep in mind, if you use a far future Expires header you have to change the component's filename whenever the component changes. You can make this step part of the build process: a version number can be embedded in the component's filename, for example, yahoo_2.0.6.js.</p>
<p>Using a far future Expires header affects page views only after a user has already visited your site. It has no effect on the number of <abbr title="Hypertext Transfer Protocol">HTTP</abbr> requests when a user visits your site for the first time and the browser's cache is empty. Therefore the impact of this performance improvement depends on how often users hit your pages with a primed cache. (A "primed cache" already contains all of the components in the page.) We <a href="http://yuiblog.com/blog/2007/01/04/performance-research-part-2/" target="_blank">measured this at Yahoo!</a> and found the number of page views with a primed cache is 75-85%. By using a far future Expires header, you increase the number of components that are cached by the browser and re-used on subsequent page views without sending a single byte over the user's Internet connection.</p>

<h3>Gzip Components</h3>
<p>The time it takes to transfer an <abbr title="Hypertext Transfer Protocol">HTTP</abbr> request and response across the network can be significantly reduced by decisions made by front-end engineers. It's true that the end-user's bandwidth speed, Internet service provider, proximity to peering exchange points, etc. are beyond the control of the development team. But there are other variables that affect response times. Compression reduces response times by reducing the size of the <abbr title="Hypertext Transfer Protocol">HTTP</abbr> response.</p>
<p>Starting with <abbr title="Hypertext Transfer Protocol">HTTP</abbr> /1.1, web clients indicate support for compression with the Accept-Encoding header in the <abbr title="Hypertext Transfer Protocol">HTTP</abbr> request.</p>
<code>Accept-Encoding: gzip, deflate</code>
<p>If the web server sees this header in the request, it may compress the response using one of the methods listed by the client. The web server notifies the web client of this via the Content-Encoding header in the response.</p>
<code>Content-Encoding: gzip</code>
<p>Gzip is the most popular and effective compression method at this time. It was developed by the GNU project and standardised by <a href="http://www.ietf.org/rfc/rfc1952.txt" target="_blank">RFC 1952</a>. The only other compression format you're likely to see is deflate, but it's less effective and less popular. </p>
<p>Gzipping generally reduces the response size by about 70%. Approximately 90% of today's Internet traffic travels through browsers that claim to support gzip. If you use Apache, the module configuring gzip depends on your version: Apache 1.3 uses <a href="http://sourceforge.net/projects/mod-gzip/" target="_blank">mod_gzip</a> while Apache 2.x uses <a href="http://httpd.apache.org/docs/2.0/mod/mod_deflate.html" target="blank">mod_deflate</a>. </p>
<p>There are known issues with browsers and proxies that may cause a mismatch in what the browser expects and what it receives with regard to compressed content. Fortunately, these edge cases are dwindling as the use of older browsers drops off. The Apache modules help out by adding appropriate Vary response headers automatically. </p>
<p>Servers choose what to gzip based on file type, but are typically too limited in what they decide to compress. Most web sites gzip their <abbr title="Hypertext Markup Language">HTML</abbr> documents. It's also worthwhile to gzip your scripts and stylesheets, but many web sites miss this opportunity. In fact, it's worthwhile to compress any text response including <abbr title="Extensible Markup Language">XML</abbr> and <abbr title="JavaScript Object Notation">JSON</abbr>. Image and <abbr title="Portable Document Format">PDF</abbr> files should not be gzipped because they are already compressed. Trying to gzip them not only wastes <abbr title="Central Processing Unit">CPU</abbr> but can potentially increase file sizes. </p>
<p>Gzipping as many file types as possible is an easy way to reduce page weight and accelerate the user experience.</p>
<p>In ASP.NET, you can use the <code>GZipStream</code> class to apply GZip encoding. However, remember <code>GZipStream</code> applies compression on the fly so there’s some overhead in the GZip encoding – you are basically adding more <abbr title="Central Processing Unit">CPU</abbr> processing to your content to reduce the output size. If your content is not that large to start with there’s probably not that much sense in compressing in the first place so whole-sale compression of dynamic content is usually not a good idea.</p>

<h3>Configure ETags</h3>
<p>Entity tags (ETags) are a mechanism that web servers and browsers use to determine whether the component in the browser's cache matches the one on the origin server. (An "entity" is another word a "component": images, scripts, stylesheets, etc.) ETags were added to provide a mechanism for validating entities that is more flexible than the last-modified date. An ETag is a string that uniquely identifies a specific version of a component. The only format constraints are that the string be quoted. The origin server specifies the component's ETag using the <code>ETag</code> response header.</p>
<p><code><abbr title="Hypertext Transfer Protocol">HTTP</abbr> /1.1 200 OK Last-Modified: Tue, 12 Dec 2006 03:03:59 GMT ETag: "10c24bc-4ab-457e1c1f" Content-Length: 12195</code></p>
<p>Later, if the browser has to validate a component, it uses the <code>If-None-Match</code> header to pass the ETag back to the origin server. If the ETags match, a 304 status code is returned reducing the response by 12195 bytes for this example.</p>
<p><code>GET /i/yahoo.gif <abbr title="Hypertext Transfer Protocol">HTTP</abbr> /1.1 Host: us.yimg.com If-Modified-Since: Tue, 12 Dec 2006 03:03:59 GMT If-None-Match: "10c24bc-4ab-457e1c1f" <abbr title="Hypertext Transfer Protocol">HTTP</abbr> /1.1 304 Not Modified</code></p>
<p>The problem with ETags is that they typically are constructed using attributes that make them unique to a specific server hosting a site. ETags won't match when a browser gets the original component from one server and later tries to validate that component on a different server, a situation that is all too common on Web sites that use a cluster of servers to handle requests. By default, both Apache and <abbr title="Internet Information Services">IIS</abbr> embed data in the ETag that dramatically reduces the odds of the validity test succeeding on web sites with multiple servers.</p>
<p>The ETag format for Apache 1.3 and 2.x is <code>inode-size-timestamp</code>. Although a given file may reside in the same directory across multiple servers, and have the same file size, permissions, timestamp, etc., its inode is different from one server to the next.</p>
<p><abbr title="Internet Information Services">IIS</abbr> 5.0 and 6.0 have a similar issue with ETags. The format for ETags on <abbr title="Internet Information Services">IIS</abbr> is <code>Filetimestamp:ChangeNumber</code>. A <code>ChangeNumber</code> is a counter used to track configuration changes to <abbr title="Internet Information Services">IIS</abbr>. It's unlikely that the <code>ChangeNumber</code> is the same across all <abbr title="Internet Information Services">IIS</abbr> servers behind a web site.</p>
<p>The end result is ETags generated by Apache and <abbr title="Internet Information Services">IIS</abbr> for the exact same component won't match from one server to another. If the ETags don't match, the user doesn't receive the small, fast 304 response that ETags were designed for; instead, they'll get a normal 200 response along with all the data for the component. If you host your web site on just one server, this isn't a problem. But if you have multiple servers hosting your web site, and you're using Apache or <abbr title="Internet Information Services">IIS</abbr> with the default ETag configuration, your users are getting slower pages, your servers have a higher load, you're consuming greater bandwidth, and proxies aren't caching your content efficiently. Even if your components have a far future <code>Expires</code> header, a conditional GET request is still made whenever the user hits Reload or Refresh.</p>
<p>If you're not taking advantage of the flexible validation model that ETags provide, it's better to just remove the ETag altogether. The <code>Last-Modified</code> header validates based on the component's timestamp. And removing the ETag reduces the size of the <abbr title="Hypertext Transfer Protocol">HTTP</abbr> headers in both the response and subsequent requests. This <a href="http://support.microsoft.com/?id=922733" target="_blank">Microsoft Support article</a> describes how to remove ETags. In Apache, this is done by simply adding the following line to your Apache configuration file: <code>FileETag none</code></p>

<h3>Flush the Buffer Early</h3>
<p>When users request a page, it can take anywhere from 200 to 500ms for the backend server to stitch together the <abbr title="Hypertext Markup Language">HTML</abbr> page. During this time, the browser is idle as it waits for the data to arrive. In PHP you have the function <a href="http://php.net/flush" target="_blank">flush()</a>. It allows you to send your partially ready <abbr title="Hypertext Markup Language">HTML</abbr> response to the browser so that the browser can start fetching components while your backend is busy with the rest of the <abbr title="Hypertext Markup Language">HTML</abbr> page. The benefit is mainly seen on busy backends or light frontends.</p>
<p>A good place to consider flushing is right after the HEAD because the <abbr title="Hypertext Markup Language">HTML</abbr> for the head is usually easier to produce and it allows you to include any <abbr title="Cascading Style Sheet">CSS</abbr> and JavaScript files for the browser to start fetching in parallel while the backend is still processing.</p>
<p>Example:</p>
<p><code>... &lt;!-- css, js --&gt; &lt;/head&gt; &lt;?php flush(); ?&gt; &lt;body&gt; ... &lt;!-- content --&gt;</code></p>

<h3>Use GET for AJAX Requests</h3>
<p>When using <code>XMLHttpRequest</code>, POST is implemented in the browsers as a two-step process: sending the headers first, then sending data. So it's best to use GET, which only takes one TCP packet to send (unless you have a lot of cookies). The maximum URL length in IE is 2K, so if you send more than 2K data you might not be able to use GET.</p>
<p>An interesting side affect is that POST without actually posting any data behaves like GET. Based on the <a href="http://www.w3.org/Protocols/rfc2616/rfc2616-sec9.html" target="_blank"><abbr title="Hypertext Transfer Protocol">HTTP</abbr> specs</a>, GET is meant for retrieving information, so it makes sense (semantically) to use GET when you're only requesting data, as opposed to sending data to be stored server-side.</p>


<h2 id="jscss">JavaScript &amp; <abbr title="Cascading Style Sheet">CSS</abbr></h2>

<h3>Make JavaScript and <abbr title="Cascading Style Sheet">CSS</abbr> External</h3>
<p>Many of these performance rules deal with how external components are managed. However, before these considerations arise you should ask a more basic question: Should JavaScript and <abbr title="Cascading Style Sheet">CSS</abbr> be contained in external files, or inlined in the page itself?</p>
<p>Using external files in the real world generally produces faster pages because the JavaScript and <abbr title="Cascading Style Sheet">CSS</abbr> files are cached by the browser. JavaScript and <abbr title="Cascading Style Sheet">CSS</abbr> that are inlined in <abbr title="Hypertext Markup Language">HTML</abbr> documents get downloaded every time the <abbr title="Hypertext Markup Language">HTML</abbr> document is requested. This reduces the number of <abbr title="Hypertext Transfer Protocol">HTTP</abbr> requests that are needed, but increases the size of the <abbr title="Hypertext Markup Language">HTML</abbr> document. On the other hand, if the JavaScript and <abbr title="Cascading Style Sheet">CSS</abbr> are in external files cached by the browser, the size of the <abbr title="Hypertext Markup Language">HTML</abbr> document is reduced without increasing the number of <abbr title="Hypertext Transfer Protocol">HTTP</abbr> requests. </p>
<p>The key factor, then, is the frequency with which external JavaScript and <abbr title="Cascading Style Sheet">CSS</abbr> components are cached relative to the number of <abbr title="Hypertext Markup Language">HTML</abbr> documents requested. This factor, although difficult to quantify, can be gauged using various metrics. If users on your site have multiple page views per session and many of your pages re-use the same scripts and stylesheets, there is a greater potential benefit from cached external files. </p>
<p>Many web sites fall in the middle of these metrics. For these sites, the best solution generally is to deploy the JavaScript and <abbr title="Cascading Style Sheet">CSS</abbr> as external files. The only exception where inlining is preferable is with home pages, such as <a href="http://www.yahoo.com" target="_blank">Yahoo!'s front page</a> and <a href="http://my.yahoo.com" target="_blank">My Yahoo!</a>. Home pages that have few (perhaps only one) page view per session may find that inlining JavaScript and <abbr title="Cascading Style Sheet">CSS</abbr> results in faster end-user response times.</p>
<p>For front pages that are typically the first of many page views, there are techniques that leverage the reduction of <abbr title="Hypertext Transfer Protocol">HTTP</abbr> requests that inlining provides, as well as the caching benefits achieved through using external files. One such technique is to inline JavaScript and <abbr title="Cascading Style Sheet">CSS</abbr> in the front page, but dynamically download the external files after the page has finished loading. Subsequent pages would reference the external files that should already be in the browser's cache.</p>

<h3>Minify JavaScript and <abbr title="Cascading Style Sheet">CSS</abbr></h3>
<p>Minification is the practice of removing unnecessary characters from code to reduce its size thereby improving load times. When code is minified all comments are removed, as well as unneeded white space characters (space, newline, and tab). In the case of JavaScript, this improves response time performance because the size of the downloaded file is reduced. Two popular tools for minifying JavaScript code are <a href="http://crockford.com/javascript/jsmin" target="_blank">JSMin</a> and <a href="http://developer.yahoo.com/yui/compressor/" target="_blank">YUI Compressor</a>. The YUI compressor can also minify <abbr title="Cascading Style Sheet">CSS</abbr>.</p>
<p>Obfuscation is an alternative optimization that can be applied to source code. It's more complex than minification and thus more likely to generate bugs as a result of the obfuscation step itself. In a survey of ten top U.S. web sites, minification achieved a 21% size reduction versus 25% for obfuscation. Although obfuscation has a higher size reduction, minifying JavaScript is less risky.</p>
<p>In addition to minifying external scripts and styles, inlined <code>&lt;script&gt;</code> and <code>&lt;style&gt;</code> blocks can and should also be minified. Even if you gzip your scripts and styles, minifying them will still reduce the size by 5% or more. As the use and size of JavaScript and <abbr title="Cascading Style Sheet">CSS</abbr> increases, so will the savings gained by minifying your code.</p>


<h2 id="css"><abbr title="Cascading Style Sheet">CSS</abbr></h2>

<h3>Put Stylesheets at the Top</h3>
<p>Moving stylesheets to the document HEAD makes pages <em>appear</em> to be loading faster. This is because putting stylesheets in the HEAD allows the page to render progressively.</p>
<p>Front-end engineers that care about performance want a page to load progressively; that is, we want the browser to display whatever content it has as soon as possible. This is especially important for pages with a lot of content and for users on slower Internet connections. The importance of giving users visual feedback, such as progress indicators, has been well researched and <a href="http://www.useit.com/papers/responsetime.html" target="_blank">documented</a>. In our case the <abbr title="Hypertext Markup Language">HTML</abbr> page is the progress indicator! When the browser loads the page progressively the header, the navigation bar, the logo at the top, etc. all serve as visual feedback for the user who is waiting for the page. This improves the overall user experience.</p>
<p>The problem with putting stylesheets near the bottom of the document is that it prohibits progressive rendering in many browsers, including Internet Explorer. These browsers block rendering to avoid having to redraw elements of the page if their styles change. The user is stuck viewing a blank white page.</p>
<p>The <a href="http://www.w3.org/TR/html4/struct/links.html#h-12.3" target="_blank"><abbr title="Hypertext Markup Language">HTML</abbr> specification</a> clearly states that stylesheets are to be included in the HEAD of the page: "Unlike A, [LINK] may only appear in the HEAD section of a document, although it may appear any number of times." Neither of the alternatives, the blank white screen or flash of unstyled content, are worth the risk. The optimal solution is to follow the <abbr title="Hypertext Markup Language">HTML</abbr> specification and load your stylesheets in the document HEAD.</p>

<h3>Choose &lt;link&gt; over @@import</h3>
<p>One of the previous best practices states that <abbr title="Cascading Style Sheet">CSS</abbr> should be at the top in order to allow for progressive rendering.</p>
<p>In IE <code>@@import</code> behaves the same as using <code>&lt;link&gt;</code> at the bottom of the page, so it's best not to use it.</p>

<h3>Avoid <abbr title="Cascading Style Sheet">CSS</abbr> Expressions</h3>
<p><abbr title="Cascading Style Sheet">CSS</abbr> expressions are a powerful (and dangerous) way to set <abbr title="Cascading Style Sheet">CSS</abbr> properties dynamically. They're supported in Internet Explorer 5+. As an example, the background color could be set to alternate every hour using <abbr title="Cascading Style Sheet">CSS</abbr> expressions.</p>
<p><code> background-color: expression( (new Date()).getHours()%2 ? "#B8D4FF" : "#F08A00" );</code></p>
<p>As shown here, the <code>expression</code> method accepts a JavaScript expression. The <abbr title="Cascading Style Sheet">CSS</abbr> property is set to the result of evaluating the JavaScript expression. The <code>expression</code> method is ignored by other browsers, so it is useful for setting properties in Internet Explorer needed to create a consistent experience across browsers.</p>
<p>The problem with expressions is that they are evaluated more frequently than most people expect. Not only are they evaluated when the page is rendered and resized, but also when the page is scrolled and even when the user moves the mouse over the page. Adding a counter to the <abbr title="Cascading Style Sheet">CSS</abbr> expression allows us to keep track of when and how often a <abbr title="Cascading Style Sheet">CSS</abbr> expression is evaluated. Moving the mouse around the page can easily generate more than 10,000 evaluations.</p>
<p>One way to reduce the number of times your <abbr title="Cascading Style Sheet">CSS</abbr> expression is evaluated is to use one-time expressions, where the first time the expression is evaluated it sets the style property to an explicit value, which replaces the <abbr title="Cascading Style Sheet">CSS</abbr> expression. If the style property must be set dynamically throughout the life of the page, using event handlers instead of <abbr title="Cascading Style Sheet">CSS</abbr> expressions is an alternative approach. If you must use <abbr title="Cascading Style Sheet">CSS</abbr> expressions, remember that they may be evaluated thousands of times and could affect the performance of your page.</p>

<h3>Avoid Filters</h3>
<p>The IE-proprietary <code>AlphaImageLoader</code> filter aims to fix a problem with semi-transparent true color <abbr title="Portable Network Graphics">PNG</abbr>s in IE versions &lt; 7. The problem with this filter is that it blocks rendering and freezes the browser while the image is being downloaded. It also increases memory consumption and is applied per element, not per image, so the problem is multiplied.</p>
<p>The best approach is to avoid <code>AlphaImageLoader</code> completely and use gracefully degrading PNG8 instead, which are fine in IE. If you absolutely need <code>AlphaImageLoader</code>, use the underscore hack <code>_filter</code> as to not penalise your IE7+ users.</p>


<h2 id="js">JavaScript</h2>

<h3>Put Scripts at the Bottom</h3>
<p>The problem caused by scripts is that they block parallel downloads. The <a href="http://www.w3.org/Protocols/rfc2616/rfc2616-sec8.html#sec8.1.4" target="_blank"><abbr title="Hypertext Transfer Protocol">HTTP</abbr> /1.1 specification</a> suggests that browsers download no more than two components in parallel per hostname. If you serve your images from multiple hostnames, you can get more than two downloads to occur in parallel. While a script is downloading, however, the browser won't start any other downloads, even on different hostnames. </p>
<p>In some situations it's not easy to move scripts to the bottom. If, for example, the script uses <code>document.write</code> to insert part of the page's content, it can't be moved lower in the page. There might also be scoping issues. In many cases, there are ways to workaround these situations.</p>
<p>An alternative suggestion that often comes up is to use deferred scripts. The <code>DEFER</code> attribute indicates that the script does not contain <code>document.write</code>, and is a clue to browsers that they can continue rendering. In Internet Explorer, the script may be deferred, but not as much as desired. If a script can be deferred, it can also be moved to the bottom of the page. That will make your web pages load faster.</p>
<p>Browser support for the <code>DEFER</code> attribute:</p>
<ul>
	<li>Chrome/Safari (WebKit): No, but supports parallel script loading, which achieves the same effect without needing to add markup</li>
	<li>Firefox 3.5+ (Gecko 1.9.1+) - Firefox 3.6+ (Gecko 1.9.2+) also supports the <abbr title="Hypertext Markup Language">HTML</abbr>5 <code>async</code> attribute</li>
	<li>Internet Explorer 4+</li>
	<li>Opera: No (Opera 10.1)</li>
</ul>

<h3>Remove Duplicate Scripts</h3>
<p>It hurts performance to include the same JavaScript file twice in one page. This isn't as unusual as you might think. A review of the ten top U.S. web sites shows that two of them contain a duplicated script. Two main factors increase the odds of a script being duplicated in a single web page: team size and number of scripts. When it does happen, duplicate scripts hurt performance by creating unnecessary <abbr title="Hypertext Transfer Protocol">HTTP</abbr> requests and wasted JavaScript execution.</p>
<p>Unnecessary <abbr title="Hypertext Transfer Protocol">HTTP</abbr> requests happen in Internet Explorer, but not in Firefox. In Internet Explorer, if an external script is included twice and is not cacheable, it generates two <abbr title="Hypertext Transfer Protocol">HTTP</abbr> requests during page loading. Even if the script is cacheable, extra <abbr title="Hypertext Transfer Protocol">HTTP</abbr> requests occur when the user reloads the page.</p>
<p>In addition to generating wasteful <abbr title="Hypertext Transfer Protocol">HTTP</abbr> requests, time is wasted evaluating the script multiple times. This redundant JavaScript execution happens in both Firefox and Internet Explorer, regardless of whether the script is cacheable.</p>
<p>One way to avoid accidentally including the same script twice is to implement a script management module in your templating system. The typical way to include a script is to use the SCRIPT tag in your <abbr title="Hypertext Markup Language">HTML</abbr> page.</p>
<p><code>&lt;script type="text/javascript" src="menu_1.0.17.js"&gt;&lt;/script&gt;</code></p>
<p>An alternative in PHP would be to create a function called <code>insertScript</code>.</p>
<p><code>&lt;?php insertScript("menu.js") ?&gt;</code></p>
<p>In addition to preventing the same script from being inserted multiple times, this function could handle other issues with scripts, such as dependency checking and adding version numbers to script filenames to support far future Expires headers.</p>

<h3>Minimise <abbr title="Document Object Model">DOM</abbr> Access</h3>
<p>Accessing <abbr title="Document Object Model">DOM</abbr> elements with JavaScript is slow so in order to have a more responsive page, you should:</p>
<ul>
	<li>Cache references to accessed elements</li>
	<li>Update nodes "offline" and then add them to the tree</li>
	<li>Avoid fixing layout with JavaScript</li>
</ul>
<p>For more information check the YUI theatre's <a href="http://yuiblog.com/blog/2007/12/20/video-lecomte/" target="_blank">"High Performance <abbr title="Asynchronous JavaScript and XML">Ajax</abbr> Applications"</a> by Julien Lecomte.</p>

<h3>Develop Smart Event Handlers</h3>
<p>Sometimes pages feel less responsive because of too many event handlers attached to different elements of the <abbr title="Document Object Model">DOM</abbr> tree which are then executed too often. That's why using <em>event delegation</em> is a good approach. If you have 10 buttons inside a <code>div</code>, attach only one event handler to the div wrapper, instead of one handler for each button. Events bubble up so you'll be able to catch the event and figure out which button it originated from.</p>
<p>You also don't need to wait for the onload event in order to start doing something with the <abbr title="Document Object Model">DOM</abbr> tree. Often all you need is the element you want to access to be available in the tree. You don't have to wait for all images to be downloaded. <code>DOMContentLoaded</code> is the event you might consider using instead of onload, but until it's available in all browsers, you can use the <a href="http://developer.yahoo.com/yui/event/" target="_blank">YUI Event</a> utility, which has an <code><a href="http://developer.yahoo.com/yui/event/#onavailable" target="_blank">onAvailable</a></code> method.</p>
<p>For more information check the YUI theatre's <a href="http://yuiblog.com/blog/2007/12/20/video-lecomte/" target="_blank">"High Performance <abbr title="Asynchronous JavaScript and XML">Ajax</abbr> Applications"</a> by Julien Lecomte.</p>


<h2 id="cookie">Cookies</h2>

<h3>Reduce Cookie Size</h3>
<p><abbr title="Hypertext Transfer Protocol">HTTP</abbr> cookies are used for a variety of reasons such as authentication and personalization. Information about cookies is exchanged in the <abbr title="Hypertext Transfer Protocol">HTTP</abbr> headers between web servers and browsers. It's important to keep the size of cookies as low as possible to minimise the impact on the user's response time.</p>
<p>For more information check <a href="http://yuiblog.com/blog/2007/03/01/performance-research-part-3/" target="_blank">"When the Cookie Crumbles"</a> by Tenni Theurer and Patty Chi. The take-home of this research:</p>
<ul>
	<li>Eliminate unnecessary cookies</li>
	<li>Keep cookie sizes as low as possible to minimise the impact on the user response time</li>
	<li>Be mindful of setting cookies at the appropriate domain level so other sub-domains are not affected</li>
	<li>Set an Expires date appropriately. An earlier Expires date or none removes the cookie sooner, improving the user response time</li>
</ul>

<h3>Use Cookie-free Domains for Components</h3>
<p>When the browser makes a request for a static image and sends cookies together with the request, the server doesn't have any use for those cookies. So they only create network traffic for no good reason. You should make sure static components are requested with cookie-free requests. Create a subdomain and host all your static components there.</p>
<p>If your domain is <code>www.example.org</code>, you can host your static components on <code>static.example.org</code>. However, if you've already set cookies on the top-level domain <code>example.org</code> as opposed to <code>www.example.org</code>, then all the requests to <code>static.example.org</code> will include those cookies. In this case, you can buy a whole new domain, host your static components there, and keep this domain cookie-free. Yahoo! uses <code>yimg.com</code>, YouTube uses <code>ytimg.com</code>, Amazon uses <code>images-amazon.com</code> and so on.</p>
<p>Another benefit of hosting static components on a cookie-free domain is that some proxies might refuse to cache the components that are requested with cookies. On a related note, if you wonder if you should use example.org or www.example.org for your home page, consider the cookie impact. Omitting www leaves you no choice but to write cookies to <code>*.example.org</code>, so for performance reasons it's best to use the www subdomain and write the cookies to that subdomain.</p>


<h2 id="images">Images</h2>

<h3>Optimise Images</h3>
<p>After a designer is done with creating the images for your web page, there are still some things you can try before you FTP those images to your web server.</p>
<ul>
	<li>You can check the <abbr title="Graphics Interchange Format"><abbr title="Graphics Interchange Format">GIF</abbr></abbr>s and see if they are using a palette size corresponding to the number of colors in the image. Using <a href="http://www.imagemagick.org" target="_blank">imagemagick</a> it's easy to check using<br /><code>identify -verbose image.gif</code><br />When you see an image useing 4 colors and a 256 color "slots" in the palette, there is room for improvement.</li>
	<li>Try converting <abbr title="Graphics Interchange Format"><abbr title="Graphics Interchange Format">GIF</abbr></abbr>s to <abbr title="Portable Network Graphics">PNG</abbr>s and see if there is a saving. More often than not, there is. Developers often hesitate to use <abbr title="Portable Network Graphics">PNG</abbr>s due to the limited support in browsers, but this is now a thing of the past. The only real problem is alpha-transparency in true color <abbr title="Portable Network Graphics">PNG</abbr>s, but then again, <abbr title="Graphics Interchange Format"><abbr title="Graphics Interchange Format">GIF</abbr></abbr>s are not true color and don't support variable transparency either. So anything a <abbr title="Graphics Interchange Format">GIF</abbr> can do, a palette <abbr title="Portable Network Graphics">PNG</abbr> (PNG8) can do too (except for animations). This simple imagemagick command results in totally safe-to-use <abbr title="Portable Network Graphics">PNG</abbr>s:<br /> <code>convert image.gif image.png</code> <br /> "All we are saying is: Give PiNG a Chance!"</li>
	<li>Run <a href="http://pmt.sourceforge.net/pngcrush/" target="_blank">pngcrush</a> (or any other <abbr title="Portable Network Graphics">PNG</abbr> optimiser tool) on all your <abbr title="Portable Network Graphics">PNG</abbr>s. Example: <br /> <code>pngcrush image.png -rem alla -reduce -brute result.png</code></li>
	<li>Run jpegtran on all your <abbr title="Joint Photographic Experts Group">JPEG</abbr>s. This tool does lossless <abbr title="Joint Photographic Experts Group">JPEG</abbr> operations such as rotation and can also be used to optimise and remove comments and other useless information (such as EXIF information) from your images. <br /> <code>jpegtran -copy none -optimise -perfect src.jpg dest.jpg</code></li>
</ul>

<h3>Optimise <abbr title="Cascading Style Sheet">CSS</abbr> Sprites</h3>
<ul>
	<li>Arranging the images in the sprite horizontally as opposed to vertically usually results in a smaller file size.</li>
	<li>Combining similar colors in a sprite helps you keep the color count low, ideally under 256 colors so to fit in a PNG8.</li>
	<li>"Be mobile-friendly" and don't leave big gaps between the images in a sprite. This doesn't affect the file size as much but requires less memory for the user agent to decompress the image into a pixel map. 100x100 image is 10 thousand pixels, where 1000x1000 is 1 million pixels</li>
</ul>

<h3>Don't Scale Images in <abbr title="Hypertext Markup Language">HTML</abbr></h3>
<p>Don't use a bigger image than you need just because you can set the width and height in <abbr title="Hypertext Markup Language">HTML</abbr>. If you need <br /> <code>&lt;img width="100" height="100" src="mycat.jpg" alt="My Cat" /&gt;</code> <br /> then your image (mycat.jpg) should be 100x100px rather than a scaled down 500x500px image.</p>

<h3>Make favicon.ico Small and Cacheable</h3>
<p>The favicon.ico is an image that stays in the root of your server. It's a necessary evil because even if you don't care about it the browser will still request it, so it's better not to respond with a <code>404 Not Found</code>. Also since it's on the same server, cookies are sent every time it's requested. This image also interferes with the download sequence, for example in IE when you request extra components in the onload, the favicon will be downloaded before these extra components.</p>
<p>So to mitigate the drawbacks of having a favicon.ico make sure:</p>
<ul>
	<li>It's small, preferably under 1K.</li>
	<li>Set Expires header with what you feel comfortable (since you cannot rename it if you decide to change it). You can probably safely set the Expires header a few months in the future. You can check the last modified date of your current favicon.ico to make an informed decision.</li>
</ul>
<p><a href="http://www.imagemagick.org/" target="_blank">Imagemagick</a> can help you create small favicons.</p>


<h2 id="mobile">Mobile</h2>

<h3>Keep Components under 25K</h3>
<p>This restriction is related to the fact that iPhone won't cache components bigger than 25K. Note that this is the <em>uncompressed</em> size. This is where minification is important because gzip alone may not be sufficient.</p>
<p>For more information check <cite><a href="http://yuiblog.com/blog/2008/02/06/iphone-cacheability/" target="_blank">Performance Research, Part 5: iPhone Cacheability - Making it Stick</a></cite> by Wayne Shea and Tenni Theurer.</p>

<h3>Pack Components into a Multipart Document</h3>
<p>Packing components into a multipart document is like an email with attachments, it helps you fetch several components with one <abbr title="Hypertext Transfer Protocol">HTTP</abbr> request (remember: <abbr title="Hypertext Transfer Protocol">HTTP</abbr> requests are expensive). When you use this technique, first check if the user agent supports it (iPhone does not).</p>

</article>
